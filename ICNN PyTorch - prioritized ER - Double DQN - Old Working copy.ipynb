{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Double DQN\n",
    "* prioritized ER (sampling of transitions with uniform weights)\n",
    "* gradient clipping\n",
    "* 3 layers, 50 hidden dim\n",
    "* $\\gamma = 0.98$\n",
    "* activation is SELU  (useful ?)\n",
    "* optimizer is Adam and learning rate is 0.0001\n",
    "* there are two losses: the MSE (Bellman) and a penalty for not being in the range (-RMAX, RMAX). The total loss is the sum of these two\n",
    "* maximum 10 steps of optimization for finding $argmax_{a}Q(s,a)$ with Rprop algorithm\n",
    "* actions are logged. As some can be zero, we replace the zeros by the minimal action taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn import ReLU, SELU\n",
    "import numpy as np\n",
    "from random import random, sample\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display, clear_output\n",
    "from parse_dataset import *\n",
    "from rank_based import *\n",
    "from icnn import ICNN, gradient_step_action, diff_params, loss_beyond_RMAX,  clip_gradients, get_q_target, update_parameters_lag\n",
    "from copy import deepcopy\n",
    "from utils import variable, moving_avg\n",
    "import rank_based\n",
    "import proportional\n",
    "from time import time\n",
    "import evaluation\n",
    "from SepsisExperienceBuffer import  SepsisExperienceBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and parse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28907991240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28917472898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('Sepsis_imp.csv')\n",
    "replace_absurd_temperatures(data)\n",
    "data = drop_patients_with_absurd_weights(data)\n",
    "data = drop_patients_with_unrealistic_HR_or_BP(data)\n",
    "data = add_relative_time_column(data)\n",
    "data = drop_patient_with_negative_input(data)\n",
    "add_small_quantities(data)\n",
    "create_action_column(data)\n",
    "add_log_actions(data)\n",
    "\n",
    "log_scaler = StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "action_scaler = StandardScaler()\n",
    "train_idx, test_idx = split_train_test_idx(data)\n",
    "\n",
    "# scale on train data only\n",
    "scaler.fit(data.loc[data.icustayid.isin(train_idx)][numerical_columns_not_to_be_logged])\n",
    "log_scaler.fit(np.log(data.loc[data.icustayid.isin(train_idx)][numerical_columns_to_be_logged]))\n",
    "action_scaler.fit(data.loc[data.icustayid.isin(train_idx)][log_action_cols])\n",
    "\n",
    "plt.hist(data.log_vaso, bins=20)\n",
    "plt.show()\n",
    "plt.hist(data.log_fluid, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28928680ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.max_dose_vaso, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx, train_idx = split_train_test_idx(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of transitions `(s,a,r,s')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Camilo\\Dropbox\\Graduate Studies\\Harvard\\CS282r RL for Healthcare\\Final Project\\cs282-f17-sebastian-camilo\\parse_dataset.py:264: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if idx == None:\n"
     ]
    }
   ],
   "source": [
    "transitions_train = transition_iterator(data, idx=train_idx, scaler=scaler, log_scaler=log_scaler,  action_scaler=action_scaler, RMAX=15, log_action=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(transitions_dict): 12224\n"
     ]
    }
   ],
   "source": [
    "transitions_dict = {k: {\n",
    "    \"s\": values[0],\n",
    "    \"a\": values[1],\n",
    "    \"r\": values[2],\n",
    "    \"s'\": values[3]   \n",
    "}\n",
    " for k, values in enumerate(transitions_train)\n",
    "}\n",
    "\n",
    "print('len(transitions_dict):',len(transitions_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute bounds for the actions (you don't have right to prescribe less than the min or more than the max). It gives bounds to the possible actions and ensure that the max of Q can actually be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min0, max0, min1, max1: -0.440594871376 3.91733713675 -1.60180774102 1.52607942065\n",
      "rmin, rmax: -15.0 15.0\n"
     ]
    }
   ],
   "source": [
    "# Compute extremums of action space\n",
    "min0 = min([d['a'][0] for k, d in transitions_dict.items()])\n",
    "max0 = max([d['a'][0] for k, d in transitions_dict.items()])\n",
    "min1 = min([d['a'][1] for k, d in transitions_dict.items()])\n",
    "max1 = max([d['a'][1] for k, d in transitions_dict.items()])\n",
    "\n",
    "print('min0, max0, min1, max1:', min0, max0, min1, max1)\n",
    "\n",
    "# Also save min and max of rewards\n",
    "rmin = min([d['r'] for k, d in transitions_dict.items()])\n",
    "rmax = max([d['r'] for k, d in transitions_dict.items()])\n",
    "print('rmin, rmax:', rmin,rmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252204it [00:01, 145338.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final length of D_train: 953\n",
      "First few episodes of D_train: [[], [(1, 0, 0, 1), (1, 0, 0, 62), (62, 4, 0, 722), (722, 4, 0, 403), (403, 4, 0, 544), (544, 4, 0, 256), (256, 4, 0, 405), (405, 4, 0, 405), (405, 4, 0, 113), (113, 4, 0, 17), (17, 4, 0, 368), (368, 4, 0, 366), (366, 4, 0, 10), (10, 4, 0, 475), (475, 4, 0, 10), (10, 3, 15, 10)]]\n"
     ]
    }
   ],
   "source": [
    "# Compute D, which is the same as transitions_train but as a list of lists where every element is an episode\n",
    "\n",
    "discrete_transitions = np.load('trajectories.npy')\n",
    "previous_id = discrete_transitions[0,0]\n",
    "D_train=[]\n",
    "episode = []\n",
    "for i,trans in tqdm(enumerate(discrete_transitions)):\n",
    "    if trans[0] in train_idx:\n",
    "        if trans[0] != previous_id:\n",
    "#             print('Appending ',len(episode),'-step episode from patient',previous_id, 'to D')\n",
    "            previous_id = trans[0]\n",
    "            D_train.append(deepcopy(episode))\n",
    "            episode = []   \n",
    "        # We're using rewards -15 and 15, so we need to correct the rewards that come with the\n",
    "        # file (was created with rewards -10 and 20)\n",
    "        if trans[3]:\n",
    "            r = trans[3]-5\n",
    "        else: r = trans[3]\n",
    "        episode.append((trans[1],trans[2], r, trans[4]))    \n",
    "\n",
    "print('Final length of D_train:',len(D_train)) \n",
    "print('First few episodes of D_train:',D_train[:2])\n",
    "\n",
    "## TODO: CHANGE TRANSITIONS SO THAT THE LAST STATE OF AN EPISODE IS STATE 751 IF ALIVE, 752 IF DEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build neural network\n",
    "The neural network is convex in $a$\n",
    "\n",
    "$$u_0 = x$$\n",
    "$$z_0 = a$$\n",
    "$$u_{i+1} = \\tilde{g}_i(\\tilde{W}_iu_i+b_i)$$\n",
    "$$z_{i+1} = g_i\\left(W_i^{(z)}(z_i \\cdot (W_i^{(zu)}u_i+b_i^{(z)})_+) + W_i^{(a)}(a \\cdot (W_i^{(au)}u_i+b_i^{(a)})) + W_i^{(u)}u_i+b_i\\right)$$\n",
    "with $$W_i^{(z)}\\geq 0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q_select = ICNN(3, 50, activation=SELU())\n",
    "Q_eval = deepcopy(Q_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Prioritized Experience Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Instance a basic PER Buffer for sepsis with low batch_size for testing\n",
    "# exp_buffer = SepsisExperienceBuffer(batch_size = batch_size, partition_num = batch_size, total_step = 260000)\n",
    "\n",
    "# # Load a small subset of transitions from dataset\n",
    "# c = 0\n",
    "# for i in transitions_dict:\n",
    "#     c = c+1\n",
    "#     if c >= 50: break  \n",
    "#     if transitions_dict[i][\"s'\"] is not None:\n",
    "#         s_prime_variable = variable(transitions_dict[i][\"s'\"]).float().resize(1,50)\n",
    "#     else:\n",
    "#         s_prime_variable = variable(np.array([50*[np.nan]])).float()\n",
    "        \n",
    "#     exp_tuple = [variable(transitions_dict[i]['s']).float().resize(1,50), \\\n",
    "#         variable(transitions_dict[i]['a']).float().resize(1,2), \\\n",
    "#         variable(transitions_dict[i]['r']).float(), \\\n",
    "#         s_prime_variable]\n",
    "    \n",
    "#     exp_buffer.store(exp_tuple)   \n",
    "    \n",
    "# # Sample elements and observe priorities\n",
    "    \n",
    "# exp, w, rank_id = exp_buffer.sample(step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get PER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create buffer with initialized priorities\n",
    "\n",
    "Can take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of experience buffer: 12096\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE SOME VARIABLES\n",
    "EPOCHS = 100\n",
    "batch_size = 128\n",
    "gamma = .98\n",
    "RMAX = 15\n",
    "c = 100.  # weight of the loss \"beyond RMAX\"\n",
    "max_steps_a = 10\n",
    "\n",
    "# CREATE PRIORITIZED ER EXPERIENCE BUFFER\n",
    "# proceed by batch\n",
    "# update the priorities immediately, so that the network starts training by looking at the good things immediately\n",
    "# CAN TAKE SOME TIME\n",
    "exp_buffer = SepsisExperienceBuffer(batch_size = batch_size, partition_num = batch_size, total_step = 260000)\n",
    "for i in range(0, len(transitions_dict), batch_size):\n",
    "    s = []\n",
    "    a = []\n",
    "    r = []\n",
    "    s_ = []\n",
    "    for j in range(0, min(batch_size, len(transitions_dict) - (i+batch_size))):\n",
    "        # check if state is terminal\n",
    "        if transitions_dict[i+j][\"s'\"] is not None:\n",
    "            s_.append(variable(transitions_dict[i+j][\"s'\"]).resize(1,50))\n",
    "        else:\n",
    "            s_.append(variable(np.array([50*[np.nan]])))\n",
    "        s.append(variable(transitions_dict[i+j]['s']).resize(1,50))\n",
    "        a.append(variable(transitions_dict[i+j]['a']).resize(1,2))\n",
    "        r.append(variable(transitions_dict[i+j]['r']))\n",
    "    if len(s) == 0:\n",
    "        break\n",
    "    s = t.cat(s)\n",
    "    a = t.cat(a)\n",
    "    r = t.cat(r)\n",
    "    s_ = t.cat(s_)\n",
    "    \n",
    "    target = get_q_target(Q_select, Q_eval, s_, r, min0, max0, min1, max1, gamma=gamma, max_steps_a=max_steps_a).squeeze()\n",
    "    pred = Q_select(s, a).squeeze()\n",
    "    td_error = ((pred - target)**2 + c*loss_beyond_RMAX(pred, RMAX).squeeze()).data.numpy() \n",
    "\n",
    "    for j in range(0, min(batch_size, len(transitions_dict) - (i+batch_size))):\n",
    "        exp_tuple = [s[j].resize(1, 50), a[j].resize(1,2), r[j].resize(1,1), s_[j].resize(1,50)]\n",
    "        exp_buffer.store(exp_tuple, td_error[j])\n",
    "        \n",
    "print('Length of experience buffer:', len(exp_buffer._buffer._experience))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(x):\n",
    "    \"\"\"\n",
    "    Clip values below -RMAX or above RMAX\n",
    "    Might be useful when the target goes beyond\n",
    "    \"\"\"\n",
    "    return x*((x>=-RMAX).float())*((x<=RMAX).float()) + RMAX*(x>RMAX).float() - RMAX*(x<-RMAX).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (2,2, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-35236b76c7e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Sample batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mt_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Camilo\\Dropbox\\Graduate Studies\\Harvard\\CS282r RL for Healthcare\\Final Project\\cs282-f17-sebastian-camilo\\SepsisExperienceBuffer.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, global_step)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mexp_ids\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mexperience\u001b[0m \u001b[0mids\u001b[0m \u001b[0mrequired\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0mlater\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Camilo\\Dropbox\\Graduate Studies\\Harvard\\CS282r RL for Healthcare\\Final Project\\cs282-f17-sebastian-camilo\\rank_based.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, global_step)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'n:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"distribution['strata_ends'][n] + 1:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'strata_ends'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"distribution['strata_ends'][n + 1]:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'strata_ends'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             index = random.randint(distribution['strata_ends'][n] + 1,\n\u001b[0;32m    170\u001b[0m                                    distribution['strata_ends'][n + 1])\n",
      "\u001b[1;32mC:\\Users\\Camilo\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36mrandint\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[1;32mC:\\Users\\Camilo\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36mrandrange\u001b[1;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;31m# Non-unit step argument supplied.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty range for randrange() (2,2, 0)"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(evaluation)\n",
    "\n",
    "# OPTIMIZER PARAMETERS\n",
    "learning_rate = 1e-4\n",
    "optimizer = t.optim.Adam(Q_select.parameters(), lr=learning_rate)\n",
    "max_steps = int(len(data) / batch_size)\n",
    "max_steps_a = 10\n",
    "\n",
    "# batch size\n",
    "batch_size= 64\n",
    "exp_buffer._buffer.batch_size = batch_size\n",
    "\n",
    "# update weights target\n",
    "T_UPDATE = 100  # parameter to copy the weights periodically\n",
    "tau = 1e-2  # rate to update target network toward primary network\n",
    "\n",
    "# monitoring\n",
    "losses = []\n",
    "average_q_pred = []\n",
    "average_q_target = []\n",
    "max_q_pred = []\n",
    "min_q_pred = []\n",
    "max_q_target = []\n",
    "min_q_target = []\n",
    "average_vaso = []\n",
    "max_vaso = []\n",
    "min_vaso = []\n",
    "average_fluid = []\n",
    "max_fluid = []\n",
    "min_fluid = []\n",
    "global_step = 0\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "for _ in range(EPOCHS):\n",
    "    t0 = time()\n",
    "    for step in range(max_steps):\n",
    "        global_step += 1\n",
    "\n",
    "        # Sample batch\n",
    "        t_sample = time()\n",
    "        exp, w, exp_id = exp_buffer.sample(global_step)\n",
    "        states = t.cat([d[0] for d in exp]).float()\n",
    "        actions = t.cat([d[1] for d in exp]).float()\n",
    "        rewards = t.cat([d[2] for d in exp]).float()\n",
    "        next_states = t.cat([d[3] for d in exp]).float()\n",
    "#         print('sample', time() - t_sample)\n",
    "        \n",
    "        # Init grad (set all of them to zero)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute loss\n",
    "        t_loss = time()\n",
    "        pred = Q_select.forward(states, actions).squeeze()  # Q(s, a)\n",
    "        target, max_actions = get_q_target(Q_select, Q_eval, next_states, rewards, min0, max0, min1, max1, gamma=gamma, max_steps_a=max_steps_a, return_max_actions=True)  # max_a' Q(s', a)\n",
    "        target = clip(target.squeeze())\n",
    "        loss = (pred - target)**2 + c*loss_beyond_RMAX(pred, RMAX).squeeze()  # this loss penalizes values that are not in the range [-rmax, rmax]\n",
    "#         print('loss', time()-t_loss)\n",
    "        \n",
    "        # Update priorities\n",
    "        t_update = time()\n",
    "        exp_buffer.update(exp_id, loss.data.numpy().tolist())\n",
    "#         print('update', time()-t_update)\n",
    "\n",
    "        loss = loss*variable(w)\n",
    "        loss = t.sum(loss)\n",
    "        \n",
    "        # Monitoring\n",
    "        losses.append(loss.data.numpy()[0]/batch_size)\n",
    "        average_q_pred.append(t.mean(pred).squeeze().data.numpy()[0])\n",
    "        max_q_pred.append(t.max(pred).squeeze().data.numpy()[0])\n",
    "        min_q_pred.append(t.min(pred).squeeze().data.numpy()[0])\n",
    "        average_q_target.append(t.mean(target).squeeze().data.numpy()[0])\n",
    "        max_q_target.append(t.max(target).squeeze().data.numpy()[0])\n",
    "        min_q_target.append(t.min(target).squeeze().data.numpy()[0])\n",
    "        min_a = np.min(max_actions.data.numpy(), 0).squeeze()\n",
    "        max_a = np.max(max_actions.data.numpy(), 0).squeeze()\n",
    "        mean_a = np.mean(max_actions.data.numpy(), 0).squeeze()\n",
    "        min_vaso.append(min_a[0])\n",
    "        max_vaso.append(max_a[0])\n",
    "        average_vaso.append(mean_a[0])\n",
    "        min_fluid.append(min_a[1])\n",
    "        max_fluid.append(max_a[1])\n",
    "        average_fluid.append(mean_a[1])\n",
    "        \n",
    "        # Compute gradients and update weights of the selection network\n",
    "        t_grad = time()\n",
    "        loss.backward()\n",
    "        clip_gradients(Q_select)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Keep weights positive so that the Q_select stays concave\n",
    "        Q_select.proj()\n",
    "#         print('grad', time()-t_grad)\n",
    "        \n",
    "        # update parameters of the evaluation network. Its weights lag behind\n",
    "        t_update_q = time()\n",
    "        if global_step % T_UPDATE == 0:\n",
    "            Q_eval = deepcopy(Q_select)\n",
    "#         update_parameters_lag(Q_select, Q_eval, tau)\n",
    "#         print('update q', time() - t_update_q)\n",
    "\n",
    "        # plot\n",
    "        if step % 250 == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.show()\n",
    "            # td error\n",
    "            plt.plot(moving_avg(np.log(losses)))\n",
    "            plt.show()\n",
    "            # Q values (target and pred)\n",
    "            plt.plot(moving_avg(average_q_pred[100:]), label='avg pred', c='darkblue')\n",
    "            plt.plot(moving_avg(min_q_pred[100:]), label='min pred', c='darkblue', alpha=.8,linestyle=':')\n",
    "            plt.plot(moving_avg(max_q_pred[100:]), label='max pred', c='darkblue', alpha=.8,linestyle=':')\n",
    "            plt.plot(moving_avg(average_q_target[100:]), label='avg target', c='crimson')\n",
    "            plt.plot(moving_avg(min_q_target[100:]), label='min target', c='crimson', alpha=.8,linestyle=':')\n",
    "            plt.plot(moving_avg(max_q_target[100:]), label='max target', c='crimson', alpha=.8,linestyle=':')\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            plt.show()\n",
    "            # actions (vaso and fluid)\n",
    "            plt.plot(moving_avg(average_fluid[100:]), label='avg fluid', c='darkblue')\n",
    "            plt.plot(moving_avg(min_fluid[100:]), label='min fluid', c='darkblue', alpha=.8,linestyle=':')\n",
    "            plt.plot(moving_avg(max_fluid[100:]), label='max fluid', c='darkblue', alpha=.8,linestyle=':')\n",
    "            plt.plot(moving_avg(average_vaso[100:]), label='avg vaso', c='crimson')\n",
    "            plt.plot(moving_avg(min_vaso[100:]), label='min vaso', c='crimson', alpha=.8,linestyle=':')\n",
    "            plt.plot(moving_avg(max_vaso[100:]), label='max vaso', c='crimson', alpha=.8,linestyle=':')\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            plt.show()\n",
    "            \n",
    "            print('Epoch %s\\n%s steps in this epoch\\n%s steps/s' % (str(_), str(step), str(step/(time()-t0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DR estimator\n",
    "extremums_of_action_space = (min0,max0,min1,max1)\n",
    "DR = evaluation.eval_ICNN_DR(Q_select, extremums_of_action_space, D_train, gamma, rmin, rmax)\n",
    "print('DR:', DR)\n",
    "plt.plot(DR)\n",
    "plt.title('DR value at step'+str(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **log batch-averaged loss** is plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_eval(next_states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_range = np.arange(min0,max0,1e-2)\n",
    "n = a_range.shape[0]\n",
    "a = variable(np.array([[aa,0.] for aa in a_range]))\n",
    "plt.plot(a_range,Q_eval(t.cat(n*[next_states[:1]]), a).squeeze().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q_eval(next_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_q_target(Q_select, Q_eval, next_states, rewards, min0, max0, min1, max1, gamma=gamma, max_steps_a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_select.forward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(Q_select.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "60000/240000*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the predictions of the model once trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.sum((Q_target.squeeze()-Q_pred.squeeze())**2 + c*loss_beyond_RMAX(Q_pred, RMAX).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q1.forward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_state_ = []\n",
    "good = dict()\n",
    "for i, s in enumerate(next_states):\n",
    "    if not np.isnan(s.data.numpy()[0]):\n",
    "        next_state_.append(s.resize(1, 50))\n",
    "        good[i] = len(good)\n",
    "\n",
    "next_state_ = t.cat(next_state_)\n",
    "max_action = variable(np.zeros((len(next_state_), 2)), requires_grad=True).float()\n",
    "prev_action = variable(np.zeros((len(next_state_), 2)), requires_grad=True).float()\n",
    "input_param = t.nn.Parameter(max_action.data)\n",
    "optimizer_for_a = t.optim.Rprop([input_param], lr=5e-1)\n",
    "for k in range(5):\n",
    "    max_action, input_param, optimizer_for_a = gradient_step_action(Q1, Q2, next_state_, max_action, min0, max0, min1, max1, input_param=input_param, optimizer=optimizer_for_a)\n",
    "    if np.max(np.abs(prev_action.data.numpy() - max_action.data.numpy())) < 1e-3:\n",
    "        break\n",
    "    prev_action = max_action * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = t.cat(np.arange(min0,max0,1e-2).shape[0]*[next_state_[0].resize(1,50)]).float()\n",
    "actions = variable(np.array([[a,0.] for a in np.arange(min0,max0,1e-2)])).float()\n",
    "Qvalues = Q1.forward(state, actions).data.numpy()\n",
    "plt.plot(np.arange(min0,max0,1e-2), Qvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing to clinician policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_mortality_vs_deviation_from_recommended_dose(data_filename, recommended_treatment__dict, make_plots = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
